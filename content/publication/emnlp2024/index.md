---
abstract: >-
  Can human reading comprehension be assessed from eye movements in reading? In this work, we address this longstanding question using large-scale eyetracking data over textual materials that are geared towards behavioral analyses of reading comprehension. We focus on a fine-grained and largely unaddressed task of predicting reading comprehension from eye movements at the level of a single question over a passage. We tackle this task using three new multimodal language models, as well as a battery of prior models from the literature. We evaluate the models' ability to generalize to new textual items, new participants, and the combination of both, in two different reading regimes, ordinary reading and information seeking. The evaluations suggest that although the task is highly challenging, eye movements contain useful signals for fine-grained prediction of reading comprehension. Code and data will be made publicly available.
slides: ""
publication_types:
  - "1"
authors:
  - Omer Shubi
  - admin
  - Cfir Avraham Hadar
  - Yevgeni Berzak
summary: This study explores whether eye movements during reading can effectively predict reading comprehension, utilizing large-scale eyetracking data and focusing on single-question assessments from text passages. The findings indicate that while the task is challenging, eye movements provide valuable signals for predicting comprehension, with evaluations conducted across various models and reading contexts, and all data and code will be made publicly available.
author_notes: []
publication: Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing
publication_short: EMNLP 2024
title: "Fine-Grained Prediction of Reading Comprehension from Eye Movements"
featured: true
doi: "https://doi.org/10.48550/arXiv.2410.04484"
tags: []
projects: []
image:
  caption: ""
  preview_only: false
date: 2024-09-20T00:00:00.000Z
url_pdf: "https://aclanthology.org/2024.emnlp-main.198.pdf"
---
